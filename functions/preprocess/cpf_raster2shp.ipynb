{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3856161a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob,os \n",
    "from rasterio.features import shapes\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "import rioxarray as xrx\n",
    "import pandas as pd, numpy as np\n",
    "from shapely.geometry import shape, Polygon, MultiPolygon\n",
    "from shapely.validation import make_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789c9244",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_dir = '/datawaha/esom/Sentinel_2/DeliRsl/RegionAll_afclean'\n",
    "tile_keys = set([ifile.split('_')[-2] for ifile in os.listdir(top_dir)])\n",
    "tile_keys = sorted(list(tile_keys))\n",
    "tile_keys[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41f5da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _fill_holes(geom):\n",
    "    \"\"\"Return geometry with all interior rings removed.\"\"\"\n",
    "    if geom.is_empty:\n",
    "        return geom\n",
    "    geom = make_valid(geom)\n",
    "    if isinstance(geom, Polygon):\n",
    "        return Polygon(geom.exterior)\n",
    "    if isinstance(geom, MultiPolygon):\n",
    "        return MultiPolygon([Polygon(p.exterior) for p in geom.geoms if not p.is_empty])\n",
    "    # For any other type (rare after polygonize), just return as-is\n",
    "    return geom\n",
    "\n",
    "\n",
    "def polygonize_fd_id(xr_tif, target_fd_type, dissolve=True):\n",
    "    \"\"\"\n",
    "    Create polygons for each unique fd_id where fd_type == target_fd_type,\n",
    "    filling holes within each polygon.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    xr_tif : xarray.Dataset\n",
    "        Raster with bands 'fd_type' and 'fd_id'\n",
    "    target_fd_type : int\n",
    "        The fd_type value to extract (e.g., 1, 2, 3...)\n",
    "    dissolve : bool\n",
    "        If True, ensures one polygon per unique fd_id\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    gpd.GeoDataFrame\n",
    "        Polygons for all fd_id matching the fd_type filter (hole-free)\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract arrays\n",
    "    fd_type = xr_tif[\"fd_type\"].values\n",
    "    fd_id = xr_tif[\"fd_id\"].values\n",
    "    transform = xr_tif.rio.transform()\n",
    "    crs = xr_tif.rio.crs\n",
    "\n",
    "    # Mask: keep only matching fd_type\n",
    "    mask = (fd_type == target_fd_type)\n",
    "\n",
    "    # Apply mask to fd_id\n",
    "    masked_fd_id = fd_id.copy()\n",
    "    masked_fd_id[~mask] = 0  # background\n",
    "\n",
    "    # Polygonize\n",
    "    polygons = []\n",
    "    ids = []\n",
    "    for geom, value in shapes(masked_fd_id, mask=mask, transform=transform):\n",
    "        if value == 0:\n",
    "            continue\n",
    "        polygons.append(shape(geom))\n",
    "        ids.append(int(value))\n",
    "\n",
    "    # Make GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame({\"fd_id\": ids, \"geometry\": polygons}, crs=crs)\n",
    "\n",
    "    # Remove holes before dissolve (cleanup small artifacts early)\n",
    "    gdf[\"geometry\"] = gdf.geometry.apply(_fill_holes)\n",
    "\n",
    "    # Optional dissolve (one polygon per fd_id)\n",
    "    if dissolve:\n",
    "        gdf = gdf.dissolve(by=\"fd_id\", as_index=False)\n",
    "        # Remove holes again in case unioning reintroduced interiors\n",
    "        gdf[\"geometry\"] = gdf.geometry.apply(_fill_holes)\n",
    "\n",
    "    # Final validity pass\n",
    "    gdf[\"geometry\"] = gdf.geometry.apply(make_valid)\n",
    "\n",
    "    return gdf\n",
    "\n",
    "# Get polygons where fd_type == 1\n",
    "def polygonize_all_fd_types(xr_tif, tile_key, year_key):\n",
    "    gdf1 = polygonize_fd_id(xr_tif, target_fd_type=1)\n",
    "    gdf1['field_type'] = 'circles'\n",
    "    gdf2 = polygonize_fd_id(xr_tif, target_fd_type=2)\n",
    "    gdf2['field_type'] = 'fans'\n",
    "    gdf5 = polygonize_fd_id(xr_tif, target_fd_type=5)\n",
    "    gdf5['field_type'] = 'merged'\n",
    "\n",
    "    # Suppose you have a list of GeoDataFrames\n",
    "    gdfs = [gdf1, gdf2, gdf5]   # add as many as you want\n",
    "    # Concatenate\n",
    "    gdf_all = pd.concat(gdfs, ignore_index=True)\n",
    "    # Ensure GeoDataFrame identity remains intact\n",
    "    gdf_all = gpd.GeoDataFrame(gdf_all, geometry=\"geometry\", crs=gdfs[0].crs)\n",
    "    gdf_all['fd_id'] = np.arange(1, len(gdf_all)+1)\n",
    "    gdf_all['Satellite Tile'] = tile_key \n",
    "    gdf_all['Year'] = year_key\n",
    "    # now add the field acreage \n",
    "    gdf_all['Acreage_m2'] = gdf_all.geometry.area\n",
    "    gdf_all['Acreage_ha'] = gdf_all['Acreage_m2'] / 10000.0\n",
    "    # round to 2 decimal places\n",
    "    gdf_all['Acreage_ha'] = gdf_all['Acreage_ha'].round(2)\n",
    "    # reporject to EPSG:4326\n",
    "    gdf_all = gdf_all.to_crs(epsg=4326)\n",
    "    # now save to shapefile\n",
    "    return gdf_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2a9915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "years = ['2019', '2020', '2021', '2022', '2023']\n",
    "\n",
    "with tqdm(total=len(years), desc=\"Years\", position=0) as year_pbar:\n",
    "    for year_key in years:\n",
    "        gdf_all = []\n",
    "\n",
    "        # inner progress bar for tiles in this year\n",
    "        with tqdm(total=len(tile_keys), desc=f\"{year_key} tiles\", position=1, leave=False) as tile_pbar:\n",
    "            for tile_key in tile_keys:\n",
    "                # find raster for this (tile, year)\n",
    "                matches = glob.glob(f\"{top_dir}/*{tile_key}_{year_key}*\")\n",
    "                if not matches:\n",
    "                    tile_pbar.write(f\"⚠️ Missing raster for tile={tile_key}, year={year_key}\")\n",
    "                    tile_pbar.update(1)\n",
    "                    continue\n",
    "\n",
    "                tif_ras = matches[0]\n",
    "                tile_pbar.set_postfix_str(f\"tile={tile_key}\")\n",
    "\n",
    "                xr_tif = xrx.open_rasterio(\n",
    "                    tif_ras, band_as_variable=True\n",
    "                ).squeeze().rename({\"band_1\": \"fd_type\", \"band_2\": \"fd_id\"})\n",
    "\n",
    "                out_gdf = polygonize_all_fd_types(xr_tif, tile_key, year_key)\n",
    "                gdf_all.append(out_gdf)\n",
    "\n",
    "                tile_pbar.update(1)\n",
    "\n",
    "        # merge and save for this year (if anything was produced)\n",
    "        if gdf_all:\n",
    "            gdf_all = pd.concat(gdf_all, ignore_index=True)\n",
    "            gdf_all = gpd.GeoDataFrame(gdf_all, geometry=\"geometry\", crs=gdf_all.crs)\n",
    "\n",
    "            out_geojson = f\"/datawaha/esom/DatePalmCounting/Geoportal/Center_pivot/year_base_consistent/CPF_fields_{year_key}.geojson\"\n",
    "            #gdf_all.to_file(out_shp)\n",
    "            gdf_all.to_file(out_geojson, driver=\"GeoJSON\")\n",
    "            tqdm.write(f\"✅ Saved: {out_geojson}\")\n",
    "        else:\n",
    "            tqdm.write(f\"ℹ️ No data to save for year {year_key}\")\n",
    "\n",
    "        year_pbar.update(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cropmapminipy311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
